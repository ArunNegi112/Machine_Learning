{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c0fd077",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "Another methond for ensemble learning - Stacking or Stacked Generalization  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c0806",
   "metadata": {},
   "source": [
    "### Concept \n",
    "remember when we used 'voting_classifier' to get the final output by hard_voting.  \n",
    "Here in stacking, instead of traditional votes, we use an ML algorithm for final output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8eeec9",
   "metadata": {},
   "source": [
    "\n",
    "### how it works\n",
    "- We split the training dataset in two subsets (subset1 and subset2)\n",
    "- Then we train the base models on subset1\n",
    "- After that we make those base models predict the instances of subset2\n",
    "- The predictions made by all base models are given as features to another model called _blender_ or _meta learner_ \n",
    "- The data given to blender have predictions of base models as features (ex: linreg_predictions, descisiontree_predictions as features) and target is original target we needed as output.\n",
    "- The blender is then trained on that dataset (with predictions from base models as features). The blender then predicts the output.\n",
    "\n",
    "- Basically, blender learns how to optimally combine predictions to make the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd70746a",
   "metadata": {},
   "source": [
    "This is a two layer prediction model.  \n",
    "There can be more layer to stacking called _multilayer stacking_ where we add more layers of blenders (uncommon though)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
